\let\textcircled=\pgftextcircled
\Chapter{Into the Rabbit Hole}{Deriving the Observable}

\epigraph{\hspace{4ex}\textit{"It was much pleasanter at home," thought poor Alice, "when one wasn't always growing larger and smaller, and being ordered about by mice and rabbits. I almost wish I hadn't gone down the rabbit-hole -- and yet -- and yet -- ..."}}{--- Lewis Carol,\\ \textit{Alice in Wonderland}}


In this chapter we are going to derive the \code{Observable} interface starting from its dual counterpart, the \code{Iterable}, which, as we have seen in Chapter \ref{chap:reactiveprogramming}, represents embodies the idea of a pull-based model of computation and is the commonly adopted solution to dealing with synchronous computations resulting in multiple values.

\section{Iterables}
\label{sec:iterables}

An \code{Iterable} is a programming construct which enables the user to traverse a collection of data, abstracting over the underlying implementation\cite{gamma1995design}.

The interface and semantics of \code{Iterable}s were first introduced by the Gang of Four though their Iterator pattern\cite{gamma1995design}; today's most used programming languages expose the \code{Iterable} as the root interface in standard Collections APIs. 

The \code{Iterable} interface is generally fixed across programming languages, with the exception of naming conventions - C\# and related languages call it IEnumerable - and slight differences in the types, as we can see from the following definitions.\\
\todo{Should I use a datatype instead of class?}

\haskellcode{src/iterable_interface.hs}\\

Although the essence of the pattern is preserved in both definitions, we claim that the C\# version more clearly and accurately reflects the way side effects play a role in the usage of the interface: \code{moveNext} contains all the side effects of walking down the underlying collection and retrieving the next value while \code{current} can inspect the retrieved value multiple times in a pure way. The Java version, on the other hand, embeds the side effect in the \code{next} function, making it impossible to inspect the current value multiple times. For this reason and without loss of generality, we will make use of the C\# definition - modulo naming conventions - in the reminder of the discussion.\\
\todo{Mention Subscription here?}

\haskellcode{src/iterable_interface_final.hs}\\

The derivation that follows will require the use of a number mathematical concepts such as categorical duality, continuations, (co)products, (un)currying, covariance, contravariance and functors. We suggest the reader to get familiar with these topics before diving into the derivation. An accessible introduction to each can be found in Appendix \ref{app:a}.

\section{The Essence of Iterables}

The first step in deriving the \code{Observable} is to simplify our \code{Iterable} definition to a type that reflects its very essence; we are gonna do this by stripping the interface presented in the previous section of all the unnecessary operational features that only clutter our definition.

Let's start by taking a closer look at the \code{Iterator} interface; we can observe that the definition of the functions \code{moveNext} and \code{current} is equivalent to a single function which returns either a value - analogous to a \code{moveNext} call returning true and a subsequent invocation to \code{current} - or nothing - analogous to a call to \code{moveNext} returning false. 

Before we formalize this observation with a proper type, let us notice another effect that is hidden in the current definition of \code{moveNext}, but not made explicit by the its type: the possibility for an exception to be thrown by the function's body. 

By merging these considerations with the notion of coproducts and Haskell's \code{Either} and \code{Maybe} type, we obtain the following definition.\\

\haskellcode{src/iterable_coproducts_maybe.hs}\\

Note how, theoretically, \code{getIterator} could also throw an exception. We assume here, without loss of generality, that the function will never throw and will always be able to return an \code{Iterator} instance.

The next step is to forget about class instances and express our interfaces as simple types.\\

\haskellcode[firstline=1,lastline=2]{src/iterable_types.hs}\\

At this point, we want to put aside the operational concerns regarding exceptions and termination and assume the \code{Iterator} function will always return a value of type \code{a}.

\haskellcode[firstline=4,lastline=5]{src/iterable_types.hs}\\

We have now reached a point where no simplification is possible anymore. The obtained types reflect the essence of the Iterator patter: an \code{Iterable} is simply a function which, when invoked, produces an \code{Iterator} and an \code{Iterator} is itself a function producing a value of type \code{a} as a side effect. 

\todo{Reformulate this part better, ask Erik for advice.}
These types present some interesting properties; let's start by analyzing the \code{Iterator}, a function which, given nothing, will produce a value of type \code{a}. This type should sound familiar to the reader acquainted with object oriented programming as it precisely describes the notion of a getter function, i.e. a lazy producer of values. When looking at the relation between the \code{Iterator} type and its base component, \code{a}, we can observe how they are bound by a covariance relation:
\todo{vending machine example?}
\begin{displaymath}
\frac{A <: B}{() \rightarrow A <: () \rightarrow B} 
\end{displaymath}

The \code{Iterable}, on the other hand, is nothing more than a getter of another getter, the \code{Iterator} and therefore abides by the covariance relation as well.

To formally prove this intuition of a covariant relation, we instantiate the \code{Iterable}/\code{Iterator} types to a covariant \code{Functor}.\\

\haskellcode[firstline=3]{src/iterable_functor.hs}\\

We will see in the next section how these concepts are relevant in expressing and motivating the relevance of the duality between Iterables and Observables.

\section{Applying Duality}

By now, the reader should be somehow familiar with the concept of duality, as it has appeared many times throughout our discussion, in concepts such as pull and push models of computation or interactive and reactive programs. Duality is, in fact, a very important general theme that has manifestations in almost every area of mathematics\cite{gowers2010princeton} (See Appendice \ref{app:a} for an introductory discussion on the topic). 

Starting from the fact that the \code{Iterable} interface embodies the idea of interactive programming, let's use the principle of duality to derive the \code{Observable} interface and see how it relates to the concept of reactive programming. In practice, this translates to the simple task of flipping the function arrows in the \code{Iterable} interface, taking us from a function resulting in a value of type \code{a} to one accepting an \code{a}.\\

\haskellcode{src/iter_to_obs.hs}\\

Not how the side effects are bound to function application rather than values, hence their flipped position in the \code{Observable} type.

The reader acquainted with functional programming will easily see the resemblance between the \code{Observable} type and a CPS function (See Appendice \ref{app:a}).\\

\haskellcode{src/obs_cont.hs}\\

It is clear how an \code{Observable} is nothing more than a CPS function where the result type \code{r} is instantiated to \code{IO ()}. To convince ourselves of this equivalence, let's think about the definition of a CPS function, i.e. a suspended computation which, given another function - the continuation - as argument, will produce its final result. This definition suits perfectly the idea behind \code{Observable} discussed in Section \ref{subsec:rx}: a function which will do nothing - i.e. is suspended - until it is subscribed to by an \code{Observer}.

A continuation, on the other hand, represents the future of the computation, a function from an intermediate result to the final result\cite{newbern-monads}; in the context of \code{Observable}s, the continuation represents the \code{Observer}, a function specifying what will happen to a value produced by the \code{Observable}, whenever it will become available, that is, whenever it will be pushed into the \code{Observer}. Since a continuation can be called multiple times within the surrounding CPS context, it is easy to see how this mathematical concept allows us to easily deal with multiple values produced at different times in the future.

In the previous section we have discussed many properties associated with \code{Iterable}s. Let's analyze now how these properties translate under dualisation and how they affect our new derived interface, the \code{Observable}.

First, moving from the observation that an \code{Iterable} is a getter of a getter, we can observe that the \code{Observable} plays exactly the opposite role, that is, a setter of a setter. The type \code{Observer :: a -> IO ()} represents, in fact, the essence of a setter function, whereas the \code{Observable} consists in nothing more than the simple task of applying the observer function to itself, producing a setter of setters. 

\todo{Probably will need to riformulate this.}
While the discussion about \code{Iterable}'s covariance was quite intuitive, things get a little bit more complicated when analyzing \code{Observable}s. Let's start by informally introducing the notion of positivity and negativity of types: we can interpret a function of type \code{f :: a -> b} as a way for us to produce a value of type \code{b}. In this context, \code{b} is considered to be positive with respect to the type \code{a -> b}. On the other hand, in order to apply the function, we are going to need a value of type \code{a}, which we will need to get from somewhere else; \code{a} is therefore considered to be negative w.r.t. the function type, as the function introduces a need for this value in order to produce a result. The point of this distinction is that positive type variables introduce a covariant relation between base and function type whereas negative type variables introduce a contravariant relation.

Analyzing \code{Iterable} within this framework is easy, the \code{Iterator} function contains a single type parameter found in a positive position, therefore resulting in a covariant relation; being the \code{Iterable} the result of applying the \code{Iterator} function to itself, we again result in a covariant relation w.r.t. the type parameter \code{a}.

The \code{Observer} function, on the contrary, introduces a need for a value of type \code{a}, resulting in a contravariant relation w.r.t. \code{a}. Again, the \code{Observable} function is the result of applying \code{Observer} to itself; surprisingly, this results in \code{a} being in a positive position. The intuition is easily understood by thinking about the rules of arithmetic multiplication: \code{a} is in negative position w.r.t. the \code{Observer} function, whereas the \code{Observer} is in negative position w.r.t. the \code{Observable}. This leads to \code{a} being negated twice, ultimately resulting in a positive position within the \code{Observable} function. Before we formalize this intuition, let's convince ourselves that \code{Observable}s effectively produces a value of type \code{a} by looking at an example:\\

\haskellcode{src/polarity.hs}\\

It is clear from this implementation that \code{randomValueObs} indeed produces a value of type \code{Int}, whereas the \code{Observer} introduces a need for such value in order to be applied. For more details on the positivity and negativity of functions and type variables, see \cite{pos-neg}\cite{pos-neg2}.

Just as we did with \code{Iterable} we can formally prove the covariant and contravariant relations by instantiating \code{Observable} to a \code{Functor} instance and \code{Observer} to a Cofunctor one (Haskell uses the name \code{Contravariant} instead).\\

\haskellcode{src/observable_functor.hs}

\section{Observables are Continuations}

\todo[inline]{Talk about the interface that we want to get, even a minimal one now and explain how this relates to the cont monad, e.g. subscribe = ContT. Introduce the ContT monad and show the minimal reference implementation.}

In the last section we mentioned how the \code{Observable} interface is equivalent to a CPS function. We are now going to formally prove this claim by providing a basic implementation of \code{Observable} as a type alias of Haskell's continuation monad. The Haskell language provides a monad construct for expressing continuations, as well as a monad transformer which allows the user to stack the functionality of continuations on top of other monads. A monad transformer is exactly what we need in order to express our \code{Observable} function producing a result in the IO monad.\\

\haskellcode[firstline=3,lastline=14]{src/observable_contT.hs}\\

At this point we have all the necessary tools to create and run an \code{Observable}.\\

\haskellcode[firstline=16]{src/observable_contT.hs}\\

Even though the above is a toy example, it shows how 

let's try with a more realistic one such that we can show that our basic implementation of rx based on continuations works just as well as a full blown one in terms of handling asynchronous data.\\ 

\todo[inline]{Put the actual demo that listens to keyboard presses. In the example, press 3 times and see that all the events are handled and none are lost.}
\haskellcode[firstline=13]{src/create_run_demo.hs}\\

\todo[inline]{Elaborate better this part. Ask Erik for input.}
It is worth noting that rx in itself is not at all async in handling data unless we use schedulers, although it doea handle asynch data. This is a common misconception, even if you have a single thread that doesn't mean you cannot handle async data, actually you are async because the control flow isn't linear. Naturally, the thing is that certain queries (the ones that don't use schedulers) will simply block your single thread and prevent other things from happening.

This demo shows exactly this, even though the processing of the data is synchronous, the data itself, being mouse movements, is inherently async.

At this point in the discussion we have a working implementation of a push based collection purely derived from the underlying theory of duality and continuations. The next step in augmenting out library is to note that continuations are monads and, being the Observable an instance of the continuation monad, it is itself a monad. This observation comes with great benefits, we can get mathematical laws - the monad laws - proven for free for our structure and, from a more practical point of view, we get functions defined for free for the Observable: fmap (from Functor), flatmap and return.

\todo[inline]{Say more on the monad laws, even if they are trivially proved.}

We will soon see how the implementation of these functions will change and move from the standard one the moment we start moving towards a more operational implementation for real world use.